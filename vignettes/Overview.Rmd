---
title: "Overview"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Overview}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Eye-movement similarity analysis

The main goal of this `eyesim` is to provide tools for computing measures of similarity between eye-movement fixation data collected over a series of trials embedded in an experimental design. A major focus of the library is to offer eay ways to compare fixation patterns between two experimental states, for example, between perceiving an image and remembering that same image. These kinds of analyses are useful in assessing and quantifying so-called eye-movement reinstatement in studies of memory. Below we describe some basic aspects of the library that should allow one to get started with it.


## A Basic unit: the fixation group

A fixation group is a set of eye-movement fixations that comprise a meaningful unit in a study, for example, a trial, a condition, a participants, a time window, etc. Every fixation group contains a set of xy coordinates and corresponding vectors indicating the `onset` (when did the fixation start?) and the `duration` (how long did the fixation last?) of the set of fixations. Below we create a fixation group from a set of 3 coordinates occurring at at times 0, 10, and 60.

After creating a `fixation_group` object, we then plot it to visualize the location of the three fixations. The size of each point is scaled by duration and the color of each point is mapped to the onset time, with yellow colors being early-courring and red colors being late-occurring in this group.


```{r}
library(eyesim)
library(patchwork)
library(dplyr)
fg <- fixation_group(x=c(-100, 0, 100), y=c(0, 100, 0), onset=c(0,10,60), duration=c(10,50,100))
plot(fg)

```

Now we create larger group consisting of 25 randomly generated eye-movements.

```{r}
library(eyesim)
cds <- do.call(rbind, lapply(1:25, function(i) {
  data.frame(x=runif(1)*100, y=runif(1)*100)
}))

onset <- cumsum(runif(25)*100)
fg <- fixation_group(x=cds[,1], y=cds[,2], onset=onset, duration=c(diff(onset),25))
plot(fg)

```

That's a pretty busy display, but captures the sequence of eye-movements. We can also plot various kinds of "density" maps which simply where the fixations were most likely to occur.

Below we show three different ways of plotting fixation density: a contour plot, a raster plot, and a filled contour plot.

```{r, fig.width=7}

p1 <- plot(fg, typ="contour", xlim=c(-10,110), ylim=c(-10,110), bandwidth=35)
p2 <- plot(fg, typ="raster", xlim=c(-10,110), ylim=c(-10,110), bandwidth=35)
p3 <- plot(fg, typ="filled_contour", xlim=c(-10,110), ylim=c(-10,110), bandwidth=35)

p1+p2+p3
```


We can also vary the bandwidth of the two-diemnsional density estimation procedure to visualize the fixations at different levels of smoothness.


```{r, fig.width=7}

p1 <- plot(fg, typ="filled_contour", xlim=c(-10,110), ylim=c(-10,110), bandwidth=20)
p2 <- plot(fg, typ="filled_contour", xlim=c(-10,110), ylim=c(-10,110), bandwidth=60)
p3 <- plot(fg, typ="filled_contour", xlim=c(-10,110), ylim=c(-10,110), bandwidth=100)

p1+p2+p3

```

## Computing similarity between fixation groups

Suppose we have to fixation groups, `fg1` and `fg2`, how do we compare these coordinate sets? Currently, `eyesim` provides methods for computing similarities between spatial density maps. In the future, other approaches will be added that incorporate temporal information. Below, we generate two eye-movement patterns, one of which is a perturbed version of the other. Then we compute a series of simialrity metrics on the two patterns.

```{r, fig.width=7}


cds <- do.call(rbind, lapply(1:25, function(i) {
  data.frame(x=runif(1)*100, y=runif(1)*100)
}))

cds2 <- do.call(rbind, lapply(1:25, function(i) {
  if (i %% 2 == 0) {
    data.frame(x=runif(1)*100, y=runif(1)*100)
  } else {
    data.frame(x=cds[i,1], y=cds[i,2])
  }
}))

onset <- cumsum(runif(25)*100)
fg1 <- fixation_group(x=cds[,1], y=cds[,2], onset=onset, duration=c(diff(onset),25))
fg2 <- fixation_group(x=cds2[,1], y=cds2[,2], onset=onset, duration=c(diff(onset),25))

p1 <- plot(fg1)
p2 <- plot(fg2)
p1+p2
```

To compute the similarity between any two `fixation_group`s we use the `similarity` generic function. First we convert the `fixation_group`s into `eye_density` objects and then compute their similarity. The default metric for comparing two density maps is the Pearson correlation coefficient.

```{r}

ed1 <- eye_density(fg1, sigma=50, xbounds=c(0,100), ybounds=c(0,100))
ed2 <- eye_density(fg2, sigma=50, xbounds=c(0,100), ybounds=c(0,100))


s1 <- similarity(ed1,ed2)
s1

```

We can compute other similarity measures as well. Below we compute similarity using the Pearson correlation, Spearman correlation, the fisher-transformed Pearson correlation, the cosine similarity, the "l1" similarity based on the 1-norm, the [Jaccard similarity](https://en.wikipedia.org/wiki/Jaccard_index) (from `proxy` package), and the [distance covariance](https://en.wikipedia.org/wiki/Distance_correlation) (`dcov` from the `energy` package).

```{r}

methods=c("pearson", "spearman", "fisherz", "cosine", "l1", "jaccard", "dcov")
for (meth in methods) {
  s1 <- similarity(ed1,ed2, method=meth)
  print(paste(meth, ":", s1))
}

```

## Computing similarity between set of fixation groups in an experiment

Suppose we have a memory experiment in which images are presented during an "encoding" block and then, during a retrieval blocks, those same images are repeated (or cued) and subjects asked to recognize (or recall) the images. In this situation, we might want to compute the pairwise similarity between encoding and retrieval trials when the image was the same. We might also want to control for non-specific eye-movement similarity between any two arbitrary encoding and retrieval trials.

Here we will simulate data from an experiment in which 50 images are shown during an encoding block and then the same 50 images are shown (or cued) during a retrieval block. We will then compute the eye-movement similarity between the encoding and retrieval trials corresponding to the same imege and the average similarity between a set of non-corresponding encoding and retrieval trials. 

We will generate data for three participants, each of which has 50 encoding and 50 retrieval trials. We will use the `eye_table` data structure, which is an extension of `data.frame` to hold the data. 


```{r}

gen_fixations <- function(imname, phase, trial, participant) {
  ## generate some number of fixation between 1 and 10
  nfix <- ceiling(runif(1) * 10)
  cds <- do.call(rbind, lapply(1:nfix, function(i) {
    data.frame(x=runif(1)*100, y=runif(1)*100)
  }))
  
  onset <- cumsum(runif(nfix)*100)
  df1 <- data.frame(x=cds[,1], y=cds[,2], onset=onset, 
                    duration=c(diff(onset),100), image=imname, 
                    phase=phase, trial=trial, participant=participant)

}

df1 <- lapply(c("s1", "s2", "s3"), function(snum) {
  lapply(c("encoding", "retrieval"), function(phase) {
    lapply(paste0(1:50), function(trial) {
      gen_fixations(paste0("im", trial), phase, trial, snum)
    }) %>% bind_rows()
  }) %>% bind_rows()
}) %>% bind_rows()

eyetab <- eye_table("x", "y", "duration", "onset", groupvar=c("participant", "phase", "image"), data=df1)

```







